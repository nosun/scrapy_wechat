## 说明
本项目为学习之用，刚开始学习爬虫，欢迎一起交流研究。

## 项目方案
通过预先设定一批公众号的 id，通过搜狗的搜索入口，进入微信的 “10篇最新文章” 列表页，进行爬取。

## 项目特点
目前没什么特点，如果不遇到验证码的情况，可以正常爬取，验证码的问题还有待解决。

## 安装及使用说明
### 一、安装 scrapy 及相关类库
### 二、clone 项目到本地
### 三、配置数据库及相关信息

## changeLog

### 20170723：

1. 基础构建及测试
2. 完成 mongodb 接入
3. 完成 mysqldb 接入
4. 完成 agent 设置测试
5. 完成 proxy 设置测试

### 20170729：

1. 引入 bs4， 完成内容处理 pipeline ，去除冗余的样式
2. 完成图片下载，但是由于效率比较低，而且经常会有异常，想后期在 web 平台使用脚本处理。
3. 增加了内容处理部分的 测试用例。
4. 修复了更新内容时的 bug。
5. 增加了 run 脚本，了解了如何使用 pycharm 进行断点调试。
6. 增加了 dbhelper 类，但是发现 twisted 的异步库类非常不容易调试，先使用 MySQLdb 类处理。

### 20170730：

1. 增加 wechat source spider，根据公众号的 "准确名称" 抓取公众号的相关信息，并存入数据库。
2. 在文章表中，增加 wid 字段，用来关联 公众号。
3. 流程上，先根据给定的一批公众号名称，通过抓取公众号，获取到公众号的信息，然后再进一步定期抓取公号的文章。


## 接下来要做的事

### 一、基本功能
1. 支持从数据库中读取公众号 target id

### 二、增强功能
1. 搜狗验证码识别
2. proxy 加强：需要支持带密码认证的方式
3. 增加分布式解决方案