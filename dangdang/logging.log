2020-11-21 23:42:17 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-21 23:42:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-21 23:42:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-21 23:42:17 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-21 23:42:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-21 23:42:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-21 23:42:18 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-21 23:42:18 [scrapy.core.engine] INFO: Spider opened
2020-11-21 23:42:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-21 23:42:18 [book] INFO: Spider opened: book
2020-11-21 23:42:18 [book] INFO: Spider opened: book
2020-11-21 23:43:08 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-21 23:43:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28517345.html> (referer: https://www.dangdang.com)
2020-11-21 23:43:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/28517345.html>
{}
2020-11-21 23:43:18 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2020-11-21 23:43:38 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-21 23:43:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/29116389.html> (referer: https://www.dangdang.com)
2020-11-21 23:43:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/29116389.html>
{}
2020-11-21 23:44:18 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 2 items (at 1 items/min)
2020-11-21 23:45:18 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 2 items (at 0 items/min)
2020-11-21 23:46:03 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-21 23:46:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28530936.html> (referer: https://www.dangdang.com)
2020-11-21 23:46:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/28530936.html>
{}
2020-11-21 23:46:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 3 items (at 1 items/min)
2020-11-21 23:47:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:48:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:49:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:50:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:51:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:52:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:53:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:54:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:55:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:56:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:57:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:58:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:59:18 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-21 23:59:46 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-21 23:59:46 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-21 23:59:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1948,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 98456,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 15, 59, 46, 880743),
 'item_scraped_count': 3,
 'log_count/DEBUG': 9,
 'log_count/INFO': 28,
 'memusage/max': 56463360,
 'memusage/startup': 54509568,
 'response_received_count': 3,
 'scheduler/dequeued/redis': 3,
 'scheduler/enqueued/redis': 3,
 'start_time': datetime.datetime(2020, 11, 21, 15, 42, 18, 119578)}
2020-11-21 23:59:46 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-21 23:59:51 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-21 23:59:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-21 23:59:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-21 23:59:51 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-21 23:59:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-21 23:59:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-21 23:59:51 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-21 23:59:51 [scrapy.core.engine] INFO: Spider opened
2020-11-21 23:59:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-21 23:59:51 [book] INFO: Spider opened: book
2020-11-21 23:59:51 [book] INFO: Spider opened: book
2020-11-21 23:59:56 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-21 23:59:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28530936.html> (referer: https://www.dangdang.com)
2020-11-21 23:59:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/28530936.html>
{}
2020-11-22 00:00:36 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:00:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28542598.html> (referer: https://www.dangdang.com)
2020-11-22 00:00:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/28542598.html>
{}
2020-11-22 00:00:51 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 2 items (at 2 items/min)
2020-11-22 00:01:28 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 00:01:28 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 00:01:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1246,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 67523,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 16, 1, 28, 259416),
 'item_scraped_count': 2,
 'log_count/DEBUG': 6,
 'log_count/INFO': 12,
 'memusage/max': 56246272,
 'memusage/startup': 54452224,
 'response_received_count': 2,
 'scheduler/dequeued/redis': 2,
 'scheduler/enqueued/redis': 2,
 'start_time': datetime.datetime(2020, 11, 21, 15, 59, 51, 419296)}
2020-11-22 00:01:28 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 00:01:33 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 00:01:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 00:01:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 00:01:33 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 00:01:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 00:01:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 00:01:33 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 00:01:33 [scrapy.core.engine] INFO: Spider opened
2020-11-22 00:01:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:01:33 [book] INFO: Spider opened: book
2020-11-22 00:01:33 [book] INFO: Spider opened: book
2020-11-22 00:01:38 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:01:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28542598.html> (referer: https://www.dangdang.com)
2020-11-22 00:01:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/28542598.html>
{}
2020-11-22 00:02:33 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2020-11-22 00:03:33 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 00:04:33 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 00:05:33 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 00:05:55 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 00:05:55 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 00:05:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 664,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 33788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 16, 5, 55, 409667),
 'item_scraped_count': 1,
 'log_count/DEBUG': 3,
 'log_count/INFO': 15,
 'memusage/max': 56197120,
 'memusage/startup': 54603776,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2020, 11, 21, 16, 1, 33, 808366)}
2020-11-22 00:05:55 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 00:05:58 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 00:05:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 00:05:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 00:05:58 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 00:05:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 00:05:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 00:05:58 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 00:05:58 [scrapy.core.engine] INFO: Spider opened
2020-11-22 00:05:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:05:58 [book] INFO: Spider opened: book
2020-11-22 00:05:58 [book] INFO: Spider opened: book
2020-11-22 00:06:08 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:06:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28542599.html> (referer: https://www.dangdang.com)
2020-11-22 00:06:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/28542599.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 34, in parse
    book.url = url
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 79, in __setattr__
    (name, value))
AttributeError: Use item['url'] = 'http://product.dangdang.com/28542599.html' to set field value
2020-11-22 00:06:42 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 00:06:42 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 00:06:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 639,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 33775,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 16, 6, 42, 631744),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'memusage/max': 54476800,
 'memusage/startup': 54476800,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 21, 16, 5, 58, 298480)}
2020-11-22 00:06:42 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 00:07:05 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 00:07:05 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 00:07:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 00:07:05 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 00:07:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 00:07:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 00:07:05 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 00:07:05 [scrapy.core.engine] INFO: Spider opened
2020-11-22 00:07:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:07:05 [book] INFO: Spider opened: book
2020-11-22 00:07:05 [book] INFO: Spider opened: book
2020-11-22 00:07:10 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:07:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28542599.html> (referer: https://www.dangdang.com)
2020-11-22 00:07:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/28542599.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 34, in parse
    book.url = url
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 79, in __setattr__
    (name, value))
AttributeError: Use item['url'] = 'http://product.dangdang.com/28542599.html' to set field value
2020-11-22 00:07:15 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:07:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28542598.html> (referer: https://www.dangdang.com)
2020-11-22 00:07:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/28542598.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 34, in parse
    book.url = url
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 79, in __setattr__
    (name, value))
AttributeError: Use item['url'] = 'http://product.dangdang.com/28542598.html' to set field value
2020-11-22 00:07:45 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 00:07:45 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 00:07:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1216,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 67562,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 16, 7, 45, 847647),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 2,
 'log_count/INFO': 11,
 'memusage/max': 54546432,
 'memusage/startup': 54546432,
 'response_received_count': 2,
 'scheduler/dequeued/redis': 2,
 'scheduler/enqueued/redis': 2,
 'spider_exceptions/AttributeError': 2,
 'start_time': datetime.datetime(2020, 11, 21, 16, 7, 5, 359821)}
2020-11-22 00:07:45 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 00:07:50 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 00:07:50 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 00:07:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 00:07:50 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 00:07:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 00:07:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 00:07:50 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 00:07:50 [scrapy.core.engine] INFO: Spider opened
2020-11-22 00:07:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:07:50 [book] INFO: Spider opened: book
2020-11-22 00:07:50 [book] INFO: Spider opened: book
2020-11-22 00:08:15 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:08:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/29116323.html> (referer: https://www.dangdang.com)
2020-11-22 00:08:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/29116323.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 34, in parse
    book.url = url
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 79, in __setattr__
    (name, value))
AttributeError: Use item['url'] = 'http://product.dangdang.com/29116323.html' to set field value
2020-11-22 00:08:50 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:09:50 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:10:01 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 00:10:01 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 00:10:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 589,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 31484,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 16, 10, 1, 873820),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 13,
 'memusage/max': 56143872,
 'memusage/startup': 54575104,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 21, 16, 7, 50, 299669)}
2020-11-22 00:10:01 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 00:10:04 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 00:10:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 00:10:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 00:10:04 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 00:10:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 00:10:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 00:10:04 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 00:10:04 [scrapy.core.engine] INFO: Spider opened
2020-11-22 00:10:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:10:04 [book] INFO: Spider opened: book
2020-11-22 00:10:04 [book] INFO: Spider opened: book
2020-11-22 00:10:09 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/28542598.html> (referer: https://www.dangdang.com)
2020-11-22 00:10:10 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/28542598.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 34, in parse
    book.url = url
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 79, in __setattr__
    (name, value))
AttributeError: Use item['url'] = 'http://product.dangdang.com/28542598.html' to set field value
2020-11-22 00:10:34 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/24144397.html> (referer: https://www.dangdang.com)
2020-11-22 00:10:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/24144397.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 34, in parse
    book.url = url
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 79, in __setattr__
    (name, value))
AttributeError: Use item['url'] = 'http://product.dangdang.com/24144397.html' to set field value
2020-11-22 00:10:52 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 00:10:52 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 00:10:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1343,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 65050,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 16, 10, 52, 829497),
 'log_count/DEBUG': 4,
 'log_count/ERROR': 2,
 'log_count/INFO': 11,
 'memusage/max': 54587392,
 'memusage/startup': 54587392,
 'response_received_count': 2,
 'scheduler/dequeued/redis': 2,
 'scheduler/enqueued/redis': 2,
 'spider_exceptions/AttributeError': 2,
 'start_time': datetime.datetime(2020, 11, 21, 16, 10, 4, 752624)}
2020-11-22 00:10:52 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 00:10:55 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 00:10:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 00:10:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 00:10:55 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 00:10:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 00:10:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 00:10:55 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 00:10:55 [scrapy.core.engine] INFO: Spider opened
2020-11-22 00:10:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:10:55 [book] INFO: Spider opened: book
2020-11-22 00:10:55 [book] INFO: Spider opened: book
2020-11-22 00:11:00 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:11:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/24144397.html> (referer: https://www.dangdang.com)
2020-11-22 00:11:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/24144397.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 34, in parse
    book.url = url
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 79, in __setattr__
    (name, value))
AttributeError: Use item['url'] = 'http://product.dangdang.com/24144397.html' to set field value
2020-11-22 00:11:25 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 00:11:25 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 00:11:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 664,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 31264,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 16, 11, 25, 804335),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'memusage/max': 54636544,
 'memusage/startup': 54636544,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 21, 16, 10, 55, 155067)}
2020-11-22 00:11:25 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 00:11:27 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 00:11:27 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 00:11:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 00:11:27 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 00:11:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 00:11:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 00:11:27 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 00:11:27 [scrapy.core.engine] INFO: Spider opened
2020-11-22 00:11:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:11:27 [book] INFO: Spider opened: book
2020-11-22 00:11:27 [book] INFO: Spider opened: book
2020-11-22 00:12:07 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:12:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/24008607.html> (referer: https://www.dangdang.com)
2020-11-22 00:12:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/24008607.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 35, in parse
    book.url = url
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 79, in __setattr__
    (name, value))
AttributeError: Use item['url'] = 'http://product.dangdang.com/24008607.html' to set field value
2020-11-22 00:12:27 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:13:12 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 00:13:12 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 00:13:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 648,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 31505,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 16, 13, 12, 639104),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'memusage/max': 56098816,
 'memusage/startup': 54550528,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 21, 16, 11, 27, 978488)}
2020-11-22 00:13:12 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 00:13:14 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 00:13:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 00:13:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 00:13:14 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 00:13:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 00:13:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 00:13:15 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 00:13:15 [scrapy.core.engine] INFO: Spider opened
2020-11-22 00:13:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 00:13:15 [book] INFO: Spider opened: book
2020-11-22 00:13:15 [book] INFO: Spider opened: book
2020-11-22 00:13:20 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 00:13:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/24008607.html> (referer: https://www.dangdang.com)
2020-11-22 00:13:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/24008607.html>
{'_id': '24008607', 'url': 'http://product.dangdang.com/24008607.html'}
2020-11-22 00:14:15 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2020-11-22 00:23:37 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 01:00:37 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 01:10:17 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 01:12:25 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 01:13:15 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 01:14:15 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 01:15:15 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 01:16:15 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 01:16:27 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 01:16:27 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 01:16:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 657,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 31510,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 17, 16, 27, 671023),
 'item_scraped_count': 1,
 'log_count/DEBUG': 3,
 'log_count/INFO': 20,
 'memusage/max': 56041472,
 'memusage/startup': 54476800,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2020, 11, 21, 16, 13, 15, 62316)}
2020-11-22 01:16:27 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 01:17:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: dangdang)
2020-11-22 01:17:48 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.7 (default, Mar 10 2020, 15:43:03) - [Clang 11.0.0 (clang-1100.0.33.17)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.2.1, Platform Darwin-19.6.0-x86_64-i386-64bit
2020-11-22 01:17:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOGSTATS_INTERVAL': 0, 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 01:17:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-11-22 01:17:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 01:17:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 01:17:50 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 01:18:35 [scrapy.core.engine] INFO: Spider opened
2020-11-22 01:18:35 [default] INFO: Spider opened: default
2020-11-22 01:18:35 [default] INFO: Spider opened: default
2020-11-22 01:54:37 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 01:54:37 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 01:54:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 01:54:37 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 01:54:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 01:54:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 01:54:37 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 01:54:37 [scrapy.core.engine] INFO: Spider opened
2020-11-22 01:54:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 01:54:37 [book] INFO: Spider opened: book
2020-11-22 01:54:37 [book] INFO: Spider opened: book
2020-11-22 01:54:57 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 01:54:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 01:54:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 58, in parse
    book_detail.css('li#detail-category-path>span.lie').xpath('a/text()').extract())
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 68, in format_book_detail
    arr = data.split('')
AttributeError: 'list' object has no attribute 'split'
2020-11-22 01:55:37 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 01:56:05 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 01:56:05 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 01:56:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 664,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 30073,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 21, 17, 56, 5, 240775),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'memusage/max': 57282560,
 'memusage/startup': 54628352,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 21, 17, 54, 37, 194027)}
2020-11-22 01:56:05 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 01:56:09 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 01:56:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 01:56:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 01:56:09 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 01:56:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 01:56:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 01:56:09 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 01:56:09 [scrapy.core.engine] INFO: Spider opened
2020-11-22 01:56:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 01:56:09 [book] INFO: Spider opened: book
2020-11-22 01:56:09 [book] INFO: Spider opened: book
2020-11-22 01:56:14 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 01:56:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 01:56:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/23417701.html>
{'_id': '23417701',
 'isbn': '23417701',
 'name': '0-43)',
 'package': '-',
 'paper': '',
 'size': '24',
 'suit': '',
 'url': 'http://product.dangdang.com/23417701.html'}
2020-11-22 01:57:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2020-11-22 02:06:47 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 02:07:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 02:54:21 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 03:04:02 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 03:04:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 04:54:38 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 08:15:02 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 08:15:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:06:30 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:07:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:08:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:09:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:10:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:11:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:12:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:13:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:14:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:15:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:16:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:17:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:18:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:19:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:20:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:47:50 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:48:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:49:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:50:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:51:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 10:52:03 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 10:52:03 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 10:52:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 648,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 30071,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 2, 52, 3, 530507),
 'item_scraped_count': 1,
 'log_count/DEBUG': 3,
 'log_count/INFO': 40,
 'memusage/max': 57331712,
 'memusage/startup': 54697984,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'start_time': datetime.datetime(2020, 11, 21, 17, 56, 9, 320805)}
2020-11-22 10:52:03 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 10:52:23 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 10:52:23 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 10:52:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-11-22 10:52:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 10:52:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 10:52:23 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 10:52:36 [scrapy.core.engine] INFO: Spider opened
2020-11-22 10:52:36 [default] INFO: Spider opened: default
2020-11-22 10:52:36 [default] INFO: Spider opened: default
2020-11-22 10:52:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://product.dangdang.com/23417701.html> (failed 1 times): DNS lookup failed: no results for hostname lookup: product.dangdang.com.
2020-11-22 10:52:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://product.dangdang.com/23417701.html> (failed 2 times): DNS lookup failed: no results for hostname lookup: product.dangdang.com.
2020-11-22 10:52:38 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://product.dangdang.com/23417701.html> (failed 3 times): DNS lookup failed: no results for hostname lookup: product.dangdang.com.
2020-11-22 21:39:15 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:39:15 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:39:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 21:39:15 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 21:39:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:39:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:39:15 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:39:15 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:39:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:39:15 [book] INFO: Spider opened: book
2020-11-22 21:39:15 [book] INFO: Spider opened: book
2020-11-22 21:39:42 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 21:39:42 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 21:39:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 13, 39, 42, 949722),
 'log_count/INFO': 11,
 'memusage/max': 54726656,
 'memusage/startup': 54726656,
 'start_time': datetime.datetime(2020, 11, 22, 13, 39, 15, 951531)}
2020-11-22 21:39:42 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 21:40:28 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:40:28 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:40:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 21:40:28 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 21:40:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:40:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:40:28 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:40:28 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:40:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:40:28 [book] INFO: Spider opened: book
2020-11-22 21:40:28 [book] INFO: Spider opened: book
2020-11-22 21:40:33 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 21:40:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 21:40:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 22, in parse
    book['author'], book['painter'], book['translator'], book['maker'] = self.parse_author_info(response)
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 141, in parse_author_info
    for k, v in type_list:
ValueError: too many values to unpack (expected 2)
2020-11-22 21:41:28 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:42:28 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:43:28 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:44:28 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:45:10 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 21:45:10 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 21:45:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 625,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 30071,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 13, 45, 10, 552009),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 15,
 'memusage/max': 57315328,
 'memusage/startup': 54661120,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2020, 11, 22, 13, 40, 28, 698001)}
2020-11-22 21:45:10 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 21:45:12 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:45:12 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:45:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 21:45:12 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 21:45:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:45:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:45:12 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:45:12 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:45:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:45:12 [book] INFO: Spider opened: book
2020-11-22 21:45:12 [book] INFO: Spider opened: book
2020-11-22 21:45:17 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 21:45:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 21:45:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 23, in parse
    book['author'], book['painter'], book['translator'], book['maker'] = self.parse_author_info(response)
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 151, in parse_author_info
    maker = author_list[k]
IndexError: list index out of range
2020-11-22 21:46:03 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 21:46:03 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 21:46:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 688,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 30070,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 13, 46, 3, 109961),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'memusage/max': 54726656,
 'memusage/startup': 54726656,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2020, 11, 22, 13, 45, 12, 573249)}
2020-11-22 21:46:03 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 21:46:16 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:46:16 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:46:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 21:46:16 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 21:46:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:46:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:46:17 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:46:17 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:46:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:46:17 [book] INFO: Spider opened: book
2020-11-22 21:46:17 [book] INFO: Spider opened: book
2020-11-22 21:46:42 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 21:46:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 21:48:00 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 21:52:55 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:52:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:52:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-11-22 21:52:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:52:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:52:55 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:53:05 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:53:05 [default] INFO: Spider opened: default
2020-11-22 21:53:05 [default] INFO: Spider opened: default
2020-11-22 21:53:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/29116389.html> (referer: https://www.dangdang.com)
2020-11-22 21:55:43 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:55:43 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:55:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 21:55:43 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 21:55:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:55:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:55:43 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:55:43 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:55:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:55:43 [book] INFO: Spider opened: book
2020-11-22 21:55:43 [book] INFO: Spider opened: book
2020-11-22 21:55:48 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 21:55:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 21:55:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 26, in parse
    book['description'] = self.get_description(response)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'BookItem does not support field: description'
2020-11-22 21:56:43 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:57:11 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 21:57:11 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 21:57:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 720,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 30071,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 13, 57, 11, 60570),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'memusage/max': 57253888,
 'memusage/startup': 54648832,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2020, 11, 22, 13, 55, 43, 329011)}
2020-11-22 21:57:11 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 21:57:13 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:57:13 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:57:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 21:57:13 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 21:57:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:57:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:57:13 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:57:13 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:57:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:57:13 [book] INFO: Spider opened: book
2020-11-22 21:57:13 [book] INFO: Spider opened: book
2020-11-22 21:57:18 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 21:57:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 21:57:18 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 32, in parse
    'category'] = self.get_book_detail(response)
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 109, in get_book_detail
    book_detail.css('li#detail-category-path>span.lie').xpath('a/text()').extract())
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 144, in format_book_detail
    arr = data.split('')
AttributeError: 'list' object has no attribute 'split'
2020-11-22 21:58:13 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:58:50 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 21:58:50 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 21:58:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 720,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 30072,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 13, 58, 50, 672831),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'memusage/max': 57479168,
 'memusage/startup': 54710272,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 22, 13, 57, 13, 375632)}
2020-11-22 21:58:50 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 21:58:52 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:58:52 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:58:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 21:58:52 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 21:58:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:58:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:58:53 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:58:53 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:58:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:58:53 [book] INFO: Spider opened: book
2020-11-22 21:58:53 [book] INFO: Spider opened: book
2020-11-22 21:58:58 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 21:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 21:58:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 34, in parse
    book['category_path'] = self.get_category_path(response)
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 98, in get_category_path
    return categories[-1][31, -5]
TypeError: string indices must be integers
2020-11-22 21:59:49 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 21:59:49 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 21:59:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 623,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 30072,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 13, 59, 49, 191197),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'memusage/max': 54812672,
 'memusage/startup': 54812672,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2020, 11, 22, 13, 58, 53, 56898)}
2020-11-22 21:59:49 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 21:59:51 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 21:59:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 21:59:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 21:59:51 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 21:59:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 21:59:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 21:59:51 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 21:59:51 [scrapy.core.engine] INFO: Spider opened
2020-11-22 21:59:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 21:59:51 [book] INFO: Spider opened: book
2020-11-22 21:59:51 [book] INFO: Spider opened: book
2020-11-22 21:59:56 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 21:59:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 21:59:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
Traceback (most recent call last):
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/middlewares.py", line 39, in process_spider_output
    for i in result:
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/nosun/data/python/scrapy/dangdang/dangdang/spiders/book.py", line 39, in parse
    yield scrapy.Request(url, callback=self.parse_book_detail(response), meta={'book': book})
  File "/Users/nosun/anaconda/envs/scrapy/lib/python3.6/site-packages/scrapy/http/request/__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got generator
2020-11-22 22:00:32 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 22:00:32 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 22:00:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 625,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 33429,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 14, 0, 32, 748437),
 'log_count/DEBUG': 2,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'memusage/max': 54792192,
 'memusage/startup': 54792192,
 'response_received_count': 1,
 'scheduler/dequeued/redis': 1,
 'scheduler/enqueued/redis': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2020, 11, 22, 13, 59, 51, 266674)}
2020-11-22 22:00:32 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 22:01:39 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 22:01:39 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 22:01:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 22:01:39 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 22:01:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 22:01:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 22:01:39 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 22:01:39 [scrapy.core.engine] INFO: Spider opened
2020-11-22 22:01:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 22:01:39 [book] INFO: Spider opened: book
2020-11-22 22:01:39 [book] INFO: Spider opened: book
2020-11-22 22:01:44 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 22:01:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 22:01:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=23417701&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.44.01.00.00> (referer: http://product.dangdang.com/23417701.html)
2020-11-22 22:01:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=23417701&mainProductId=23417701&categoryPath=01.41.44.01.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish> (referer: http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=23417701&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.44.01.00.00)
2020-11-22 22:01:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/index.php?r=comment%2Flist&productId=23417701&mainProductId=23417701&categoryPath=01.41.44.01.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
{'_id': '23417701',
 'author': '[]   ',
 'author_detail': '',
 'catalog': '<p>04. 1 '
            '</p><p>\n'
            '</p><p>04. 2 '
            '</p><p>\n'
            '</p><p>04. 3 '
            '</p>',
 'category': ['',
              '',
              '',
              '',
              '',
              '',
              '0-2',
              '',
              '',
              '',
              '/'],
 'category_path': '01.41.44.01.00.00',
 'comments_info': {'autoCount': '377920',
                   'average_score': '5',
                   'average_score_eliminate_default': '4.7',
                   'favorable_rate': '1',
                   'goodRate': '99.9',
                   'long_comment_count': '1',
                   'main_product_id': '23417701',
                   'pageCount': '3693',
                   'pageIndex': '1',
                   'total_all_comment_num': '414848',
                   'total_auto_count': '377920',
                   'total_comment_num': '414847',
                   'total_crazy_count': '414409',
                   'total_detest_count': '135',
                   'total_image_count': '844',
                   'total_indifferent_count': '301',
                   'total_score_count': '36137'},
 'content': '<p>0-4</p><p>*</p><p></p><p></p><p>http://m.ximalaya.com/ertong/15953492/</p><p>0-4</p><p>\n'
            '</p><p>*</p><p>\n'
            '</p><p></p><p></p><p>\n'
            '</p><p></p><p>\n'
            '</p><p></p><p>http://m.ximalaya.com/ertong/15953492/</p><p>\n'
            '</p><p>\n'
            '</p><p>\n'
            '</p><p> \xa0</p><p>\n'
            '</p><p>\n'
            '</p><p>\n'
            '</p><p>\n'
            '</p><p>\n'
            '</p><p>\n'
            '</p><p></p>',
 'description': '600(0-3)()',
 'editor_recommendation': '<p>\n'
                          '</p><p>0-410035</p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p>910</p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p>0-45</p><p>\xa0</p><p>\n'
                          '</p><p>\xa0</p>',
 'images': ['http://img3m1.ddimg.cn/43/31/23417701-1_u_7.jpg',
            'http://img3m1.ddimg.cn/43/31/23417701-2_u_4.jpg',
            'http://img3m1.ddimg.cn/43/31/23417701-3_u_4.jpg',
            'http://img3m1.ddimg.cn/43/31/23417701-4_u_4.jpg',
            'http://img3m1.ddimg.cn/43/31/23417701-5_u_3.jpg',
            'http://img3m1.ddimg.cn/43/31/23417701-6_u_3.jpg',
            'http://img3m1.ddimg.cn/43/31/23417701-7_u_3.jpg',
            'http://img3m1.ddimg.cn/43/31/23417701-8_u_3.jpg'],
 'isbn': '23417701',
 'media_review': '',
 'name': '0-43)',
 'package': '-',
 'paper': '',
 'press': '',
 'price': 0,
 'pub_date': '201402',
 'sell_price': '93.10',
 'size': '24',
 'suit': '',
 'url': 'http://product.dangdang.com/23417701.html'}
2020-11-22 22:02:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 1 items (at 1 items/min)
2020-11-22 22:03:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 22:04:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 22:05:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 22:06:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 22:07:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 22:08:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 22:09:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 22:10:31 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 22:10:31 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 22:10:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2355,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 75502,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 14, 10, 31, 212867),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 19,
 'memusage/max': 57856000,
 'memusage/startup': 54661120,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued/redis': 3,
 'scheduler/enqueued/redis': 3,
 'start_time': datetime.datetime(2020, 11, 22, 14, 1, 39, 370156)}
2020-11-22 22:10:31 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 22:10:48 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 22:10:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter', 'LOGSTATS_INTERVAL': 0, 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 22:10:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage']
2020-11-22 22:10:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 22:10:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 22:10:48 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 22:10:57 [scrapy.core.engine] INFO: Spider opened
2020-11-22 22:10:57 [default] INFO: Spider opened: default
2020-11-22 22:10:57 [default] INFO: Spider opened: default
2020-11-22 22:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/23417701.html> (referer: https://www.dangdang.com)
2020-11-22 22:15:42 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 22:15:42 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 22:15:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 22:15:42 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 22:15:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 22:15:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 22:15:42 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 22:15:42 [scrapy.core.engine] INFO: Spider opened
2020-11-22 22:15:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 22:15:42 [book] INFO: Spider opened: book
2020-11-22 22:15:42 [book] INFO: Spider opened: book
2020-11-22 22:16:07 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 22:16:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/29116389.html> (referer: https://www.dangdang.com)
2020-11-22 22:16:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=29116389&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.05.03.00.00> (referer: http://product.dangdang.com/29116389.html)
2020-11-22 22:16:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=29116389&mainProductId=29116389&categoryPath=01.41.05.03.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish> (referer: http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=29116389&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.05.03.00.00)
2020-11-22 22:16:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/index.php?r=comment%2Flist&productId=29116389&mainProductId=29116389&categoryPath=01.41.05.03.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
{'_id': '29116389',
 'author': '[][][] ',
 'author_detail': '<p>50</p><p>[]\xa0'
                  '</p><p>1945 '
                  '400 '
                  '\u3000'
                  '</p><p>[]</p><p>1943 '
                  '1967 '
                  '</p>',
 'catalog': '',
 'category': '>>/>>>3-6>/>>',
 'category_path': '01.41.05.03.00.00',
 'comments_info': {'autoCount': '1098',
                   'average_score': '4.98',
                   'average_score_eliminate_default': '4.87',
                   'favorable_rate': '1',
                   'goodRate': '99.6',
                   'long_comment_count': '0',
                   'main_product_id': '29116389',
                   'pageCount': '5',
                   'pageIndex': '1',
                   'total_auto_count': '1098',
                   'total_comment_num': '1144',
                   'total_crazy_count': '1139',
                   'total_detest_count': '1',
                   'total_image_count': '12',
                   'total_indifferent_count': '0',
                   'total_score_count': '42'},
 'content': '<p>* 1969 '
            ' 600  50 </p><p>\u3000\u3000'
            '12</p><p>\u3000\u3000'
            '</p><p> X '
            '</p><p></p><p> '
            '</p><p>\xa0 \xa0 '
            '* 1969 '
            ' 600  50 </p><p>\u3000\u3000'
            '12</p><p>\u3000\u3000'
            '</p><p> X '
            '</p><p></p><p> '
            '</p><p></p><p></p><p>\xa0'
            '</p><p> '
            '</p><p>*</p><p></p><p>\n'
            '</p><p>  \xa0'
            '</p><p>X</p><p></p><p>\n'
            '</p><p> </p><p>\xa0'
            '</p><p>\n'
            '</p><p></p><p> \xa0'
            '14</p><p>\n'
            '</p><p> \xa0'
            '</p><p></p><p>*</p><p>\n'
            '</p><p> \xa0'
            '</p><p></p><p></p><p> \xa0 '
            ' \xa0\xa0</p><p></p>',
 'description': '5036JD',
 'editor_recommendation': '<p>50</p><p></p><p>JDMichaelV10</p><p></p><p>36</p><p></p><p></p><p>\n'
                          '</p><p></p><p>*50*</p><p>slogan: '
                          '</p><p>\xa0'
                          '</p>',
 'images': ['http://img3m9.ddimg.cn/93/16/29116389-1_u_12.jpg',
            'http://img3m9.ddimg.cn/93/16/29116389-2_u_6.jpg',
            'http://img3m9.ddimg.cn/93/16/29116389-3_u_6.jpg',
            'http://img3m9.ddimg.cn/93/16/29116389-4_u_5.jpg',
            'http://img3m9.ddimg.cn/93/16/29116389-5_u_6.jpg',
            'http://img3m9.ddimg.cn/93/16/29116389-6_u_6.jpg',
            'http://img3m9.ddimg.cn/93/16/29116389-7_u_6.jpg',
            'http://img3m9.ddimg.cn/93/16/29116389-8_u_6.jpg'],
 'isbn': '9787544866071',
 'media_review': '<p>**</p><p></p><p> '
                 '  </p><p>  '
                 '</p><p> '
                 ' '
                 '</p><p>**</p><p></p><p>\n'
                 '</p><p></p><p>\xa0'
                 ' \xa0</p><p>\n'
                 '</p><p>\xa0 '
                 '</p><p>\xa0'
                 ' '
                 '</p><p>\xa0 '
                 ' \xa0</p><p>\n'
                 '</p><p>\xa0 \xa0 '
                 '50*</p><p>\xa0 '
                 ' </p><p>\n'
                 '</p><p>\xa0 \xa0 '
                 '201950*</p><p>\xa0 \xa0 '
                 '</p><p>\xa0 \xa0 '
                 '38*</p><p> '
                 '</p><p>\n'
                 '</p><p>\xa0</p><p></p>',
 'name': '12',
 'package': '',
 'paper': '',
 'press': '',
 'price': '300.00',
 'pub_date': '202008',
 'sell_price': '300.00',
 'size': '12',
 'suit': '',
 'url': 'http://product.dangdang.com/29116389.html'}
2020-11-22 22:16:27 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 22:16:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/25293542.html#ddclick_reco_reco_alsoview> (referer: https://www.dangdang.com)
2020-11-22 22:16:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=25293542&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.48.07.00.00> (referer: http://product.dangdang.com/25293542.html)
2020-11-22 22:16:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25293542&mainProductId=25293542&categoryPath=01.41.48.07.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish> (referer: http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=25293542&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.48.07.00.00)
2020-11-22 22:16:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/index.php?r=comment%2Flist&productId=25293542&mainProductId=25293542&categoryPath=01.41.48.07.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
{'_id': '25293542',
 'author': '',
 'author_detail': '',
 'catalog': '',
 'category': '>>>>>3-6>>>',
 'category_path': '01.41.48.07.00.00',
 'comments_info': {'autoCount': '35434',
                   'average_score': '4.87',
                   'average_score_eliminate_default': '4.56',
                   'favorable_rate': '1',
                   'goodRate': '99.9',
                   'long_comment_count': '1',
                   'main_product_id': '25293542',
                   'pageCount': '82',
                   'pageIndex': '1',
                   'total_all_comment_num': '36254',
                   'total_auto_count': '35434',
                   'total_comment_num': '36253',
                   'total_crazy_count': '36216',
                   'total_detest_count': '24',
                   'total_image_count': '242',
                   'total_indifferent_count': '8',
                   'total_score_count': '775'},
 'content': '',
 'description': '3+22',
 'editor_recommendation': '',
 'images': ['http://img3m2.ddimg.cn/32/9/25293542-1_u_24.jpg',
            'http://img3m2.ddimg.cn/32/9/25293542-2_u_12.jpg',
            'http://img3m2.ddimg.cn/32/9/25293542-3_u_7.jpg',
            'http://img3m2.ddimg.cn/32/9/25293542-4_u_5.jpg'],
 'isbn': '9787549971497',
 'media_review': '',
 'name': '1111',
 'package': '',
 'paper': '',
 'press': '',
 'price': '798.00',
 'pub_date': '201804',
 'sell_price': '292.70',
 'size': '4',
 'suit': '',
 'url': 'http://product.dangdang.com/25293542.html#ddclick_reco_reco_alsoview'}
2020-11-22 22:16:42 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 2 items (at 2 items/min)
2020-11-22 22:17:02 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 22:17:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/27868866.html> (referer: https://www.dangdang.com)
2020-11-22 22:17:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=27868866&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.44.13.00.00> (referer: http://product.dangdang.com/27868866.html)
2020-11-22 22:17:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=27868866&mainProductId=27868866&categoryPath=01.41.44.13.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish> (referer: http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=27868866&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.44.13.00.00)
2020-11-22 22:17:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/index.php?r=comment%2Flist&productId=27868866&mainProductId=27868866&categoryPath=01.41.44.13.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
{'_id': '27868866',
 'author': '[] /  ',
 'author_detail': '<p>\xa0</p>',
 'catalog': '<p>\xa0 \xa04</p><p>\n'
            '</p><p>\xa0 \xa05</p><p>\n'
            '</p><p>\xa0 \xa0 \xa0 6</p><p>\n'
            '</p><p>9</p><p>\n'
            '</p><p>2</p><p>\n'
            '</p><p></p><p>\n'
            '</p><p></p><p>\n'
            '</p><p></p>',
 'category': '>>>>>0-2>>>/',
 'category_path': '01.41.44.13.00.00',
 'comments_info': {'autoCount': '298471',
                   'average_score': '4.86',
                   'average_score_eliminate_default': '4.52',
                   'favorable_rate': '1',
                   'goodRate': '99.9',
                   'long_comment_count': '2',
                   'main_product_id': '27868866',
                   'pageCount': '932',
                   'pageIndex': '1',
                   'total_all_comment_num': '307785',
                   'total_auto_count': '298471',
                   'total_comment_num': '307783',
                   'total_crazy_count': '307444',
                   'total_detest_count': '160',
                   'total_image_count': '690',
                   'total_indifferent_count': '177',
                   'total_score_count': '9302'},
 'content': '<p>290~40~40~21~33 '
            '00</p><p>\n'
            '</p><p>\xa0</p><p>\n'
            '</p><p>\xa0\xa0\xa0\xa0'
            '</p>',
 'description': '0~4500',
 'editor_recommendation': '<p>\n'
                          '</p><p>1290~40</p><p>\n'
                          '</p><p>20~21~33 '
                          '290~4</p><p>300</p><p>4</p><p>\n'
                          '</p><p>5</p><p></p><p></p><p>\n'
                          '</p><p>\xa0</p>',
 'images': ['http://img3m6.ddimg.cn/69/22/27868866-1_u_89.jpg',
            'http://img3m6.ddimg.cn/69/22/27868866-2_u_20.jpg',
            'http://img3m6.ddimg.cn/69/22/27868866-3_u_23.jpg',
            'http://img3m6.ddimg.cn/69/22/27868866-4_u_18.jpg'],
 'isbn': '9787553510156',
 'media_review': '',
 'name': '8',
 'package': '',
 'paper': '',
 'press': '',
 'price': '978.80',
 'pub_date': '201905',
 'sell_price': '880.90',
 'size': '48',
 'suit': '',
 'url': 'http://product.dangdang.com/27868866.html'}
2020-11-22 22:17:42 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 3 pages/min), scraped 3 items (at 1 items/min)
2020-11-22 22:18:42 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-22 22:19:42 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-22 22:20:42 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-22 22:21:42 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 0 pages/min), scraped 3 items (at 0 items/min)
2020-11-22 22:22:07 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 22:22:07 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 22:22:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7211,
 'downloader/request_count': 9,
 'downloader/request_method_count/GET': 9,
 'downloader/response_bytes': 223459,
 'downloader/response_count': 9,
 'downloader/response_status_count/200': 9,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 14, 22, 7, 187763),
 'item_scraped_count': 3,
 'log_count/DEBUG': 15,
 'log_count/INFO': 17,
 'memusage/max': 60526592,
 'memusage/startup': 54681600,
 'request_depth_max': 2,
 'response_received_count': 9,
 'scheduler/dequeued': 9,
 'scheduler/dequeued/memory': 9,
 'scheduler/enqueued': 9,
 'scheduler/enqueued/memory': 9,
 'start_time': datetime.datetime(2020, 11, 22, 14, 15, 42, 445029)}
2020-11-22 22:22:07 [scrapy.core.engine] INFO: Spider closed (shutdown)
2020-11-22 22:22:10 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: dangdang)
2020-11-22 22:22:10 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'dangdang', 'COOKIES_ENABLED': False, 'DOWNLOAD_DELAY': 1, 'LOG_ENABLED': False, 'LOG_FILE': 'logging.log', 'NEWSPIDER_MODULE': 'dangdang.spiders', 'SPIDER_MODULES': ['dangdang.spiders'], 'USER_AGENT': 'dangdang (+http://www.yourdomain.com)'}
2020-11-22 22:22:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-11-22 22:22:10 [book] INFO: Reading start URLs from redis key 'book:start_urls' (batch size: 16, encoding: utf-8
2020-11-22 22:22:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['dangdang.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'dangdang.middlewares.DangdangDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-22 22:22:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'dangdang.middlewares.DangdangSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-22 22:22:10 [scrapy.middleware] INFO: Enabled item pipelines:
['dangdang.pipelines.DangdangPipeline']
2020-11-22 22:22:10 [scrapy.core.engine] INFO: Spider opened
2020-11-22 22:22:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-22 22:22:10 [book] INFO: Spider opened: book
2020-11-22 22:22:10 [book] INFO: Spider opened: book
2020-11-22 22:22:45 [book] DEBUG: Read 1 requests from 'book:start_urls'
2020-11-22 22:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/27874767.html> (referer: https://www.dangdang.com)
2020-11-22 22:22:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=callback%2Fdetail&productId=27874767&templateType=publish&describeMap=&shopId=0&categoryPath=01.41.48.02.00.00> (referer: http://product.dangdang.com/27874767.html)
2020-11-22 22:22:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=27874767&mainProductId=27874767&categoryPath=01.41.48.02.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish> (referer: http://product.dangdang.com/27874767.html)
2020-11-22 22:22:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://product.dangdang.com/index.php?r=comment%2Flist&productId=27874767&mainProductId=27874767&categoryPath=01.41.48.02.00.00&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
{'_id': '27874767',
 'author': 'DK ',
 'author_detail': '<p>DK1974DK</p><p>\xa0'
                  '</p>',
 'catalog': '',
 'category': '>>>//>>3-6>',
 'category_path': '01.41.48.02.00.00',
 'comments_info': {'autoCount': '8515',
                   'average_score': '4.97',
                   'average_score_eliminate_default': '4.93',
                   'favorable_rate': '1',
                   'goodRate': '99.8',
                   'long_comment_count': '0',
                   'main_product_id': '27874767',
                   'pageCount': '49',
                   'pageIndex': '1',
                   'total_auto_count': '8515',
                   'total_comment_num': '8998',
                   'total_crazy_count': '8983',
                   'total_detest_count': '4',
                   'total_image_count': '70',
                   'total_indifferent_count': '11',
                   'total_score_count': '467'},
 'content': '<p></p><p>\n'
            '</p><p>DK04</p><p>\n'
            '</p><p></p><p>\n'
            '</p><p>640150300500</p><p>\n'
            '</p><p></p><p>\n'
            '</p><p>\xa0</p>',
 'description': 'DK '
                '0-4',
 'editor_recommendation': '<p>1.DK</p><p>DK</p><p></p><p>2.</p><p> '
                          '</p><p>3.</p><p> '
                          '  '
                          '</p><p></p><p></p><p></p><p></p><p>4.04</p><p></p><p>5.</p><p></p><p></p><p>6.</p><p></p><p>1.DK</p><p></p><p>\n'
                          '</p><p>DK</p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p>2.</p><p></p><p>\n'
                          '</p><p> '
                          '</p><p>\n'
                          '</p><p>3.</p><p></p><p>\n'
                          '</p><p>   '
                          '</p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p>4.</p><p>04</p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p>5.</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p>6.</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p>7.</p><p></p><p>\n'
                          '</p><p></p><p>\n'
                          '</p><p>8.</p><p></p><p>\n'
                          '</p><p></p><p>\xa0'
                          '</p><p></p>',
 'images': ['http://img3m7.ddimg.cn/30/3/27874767-1_u_19.jpg',
            'http://img3m7.ddimg.cn/30/3/27874767-2_u_5.jpg',
            'http://img3m7.ddimg.cn/30/3/27874767-3_u_6.jpg',
            'http://img3m7.ddimg.cn/30/3/27874767-4_u_6.jpg',
            'http://img3m7.ddimg.cn/30/3/27874767-5_u_6.jpg',
            'http://img3m7.ddimg.cn/30/3/27874767-6_u_6.jpg',
            'http://img3m7.ddimg.cn/30/3/27874767-7_u_6.jpg',
            'http://img3m7.ddimg.cn/30/3/27874767-8_u_3.jpg'],
 'isbn': '9787304097684',
 'media_review': '',
 'name': 'DK6',
 'package': '-',
 'paper': '',
 'press': '',
 'price': '228.00',
 'pub_date': '201909',
 'sell_price': '205.20',
 'size': '24',
 'suit': '',
 'url': 'http://product.dangdang.com/27874767.html'}
2020-11-22 22:23:10 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 1 items (at 1 items/min)
2020-11-22 22:24:10 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2020-11-22 22:24:29 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2020-11-22 22:24:29 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-11-22 22:24:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2233,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 74914,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 11, 22, 14, 24, 29, 773341),
 'item_scraped_count': 1,
 'log_count/DEBUG': 5,
 'log_count/INFO': 13,
 'memusage/max': 57704448,
 'memusage/startup': 54788096,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2020, 11, 22, 14, 22, 10, 350865)}
2020-11-22 22:24:29 [scrapy.core.engine] INFO: Spider closed (shutdown)
